---
title: "K Means Application : Data Science Capstone"
author: "Lindsay Guyette, Alondra Nunez, Chantal Ojurongbe, Jonathan Broada"
date: '`r Sys.Date()`'
format: revealjs
course: STA 6257 - Advanced Statistical Modeling
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

## Introduction 

**Clustering** is the process of grouping similar objects or data points together based on their characteristics or attributes. Clustering aims to identify inherent clusters in a dataset where the data points within each cluster exhibit a strong resemblance, yet the clusters themselves are clearly dissimilar from one another.

## K-means Clustering

The term "k-Means Clustering" refers to a method used in data analysis and machine learning to partition a set of data points into k distinct clusters.The method operates in an iterative manner, assigning each data point to one of k clusters based on the given attributes. The main concept is to establish k centroids, representing each cluster, and allocate each data point to the centroid that is closest to it. This allocation is done in a way that minimizes the total squared distances between the data points and their respective centroids.

K-means clustering can be applied to a wide variety of data, including bioinformatics, sociology, and in economics.

## Bioinformatics

K-means clustering is one type of data analysis technique that can be used to group differential gene/protein expression according to specific phenotypes, or physical presentations of biological traits. For instance, this can be used to assign cells to specific types based on single-cell RNA sequencing data, which measures the total gene expression for thousands of genes within a single cell. Yang et al., 2017 utilized k-means clustering to analyze the scRNA sequencing data of hundreds of cell types to develop a novel algorithm that identifies the optimal sets of genes to cluster single cells into distinct biological groups.

## Sociology

Additionally, k-means clustering can be applied to population-level data to determine significant groupings related to **socioeconomic outcomes.** The factors related to socioeconomic mobility were evaluated in a 2023 study using longitudinal data from the Opportunity Atlas project. Here, k-means clustering revealed differences in socioeconomic mobility related to geographic location, income, and neighborhood factors such as poverty rate and incarceration rates [@zelasky_identifying_2023].

## Economics

In 2017, food market researchers used k-means clustering to segment the organic food market in Lebanon. By starting with 13 variables, they applied Principal Component Analysis (PCA) to reduce the number while retaining the explanatory power. The k-means algorithm was then employed, resulting in four distinct clusters of consumer opinions on organic food. Each cluster was labeled appropriately to facilitate understanding and application in research. The outcomes present relevant groups that can guide policy and initiatives in the organic food market in Lebanon [@tleis_segmenting_2017].

## Modifications of K-means

Variations and enhancements of the k-means clustering algorithm have been thoroughly researched. The k-means algorithm was originally proposed in in the 1950s and due to its computational simplicity, it has many challenges (like having to select the number of clusters, or minimal local convergence because of the random initial centroids) many variants of k-means have been created to tackle those challenges and broaden the applicability of k-means [@ikotun_k-means_2023].

## Modification of K-means

Variations and enhancements of the k-means clustering algorithm have been thoroughly researched. The k-means algorithm was originally proposed in in the 1950s and due to its computational simplicity, it has many challenges (like having to select the number of clusters, or minimal local convergence because of the random initial centroids) many variants of k-means have been created to tackle those challenges and broaden the applicability of k-means [@ikotun_k-means_2023].

## Modification of k-means

Yang et al propose a new method on selecting the optimal k value by addressing both application-specific and detector-specific factors. The authors proposed the KFC method which offers a parameter free solution with linear time complexity. Yang et al made the KFC method available at www.outliernet.com to an external site to facilitate reproducibility and provide opportunities for others to expand their research. Their research showed that the KFC method outperforms traditional methods and is much more versatile making it useful across many fields [@yang_outlier_2023].

## Methods

The k-means clustering algorithm can be analytically defined as an optimization problem. The objective is to divide a collection of n data points into k clusters in a manner that minimizes the sum of squares inside each cluster (WCSS). The goal of k-means is to minimize the total sum of squared distances between each data point and its corresponding cluster centroid. The **within-cluster sum of squares (WCSS)** represents this.

## Methods {.smaller}

$$\text{WCSS} = \sum_{j=1}^{k}\sum_{xi\in Cj}^{} \left\| x_{i} - \mu_{j} \right\|^2$$

where: C~j~ is the set of data points assigned to cluster j, x~i~ is a data point, Œº~j‚Äã~ is the centroid of cluster j, ‚à•x~i~‚àíŒº~j~‚à• is the Euclidean distance between data point x~i~‚Äã and centroid Œº~j~‚Äã. Mathematical representation of the algorithm. Algorithm Steps in Mathematical Terms Initialization Randomly choose k initial centroids Œº~1~,Œº~2~,...,Œº~k‚Äã~ from the dataset {x~1~,x~2~,...,x~n~}. Assignment Step Assign each data point x~i‚Äã~ to the nearest centroid Œº~j~‚Äã. This can be mathematically expressed as: C~j~ = {x~i~ : ‚à•x~i~‚àíŒº~j~‚à•2 ‚â§ ‚à•x~i~‚àíŒº~l~‚à•2 for all l, 1 ‚â§ l ‚â§ k} Here, C~j‚Äã~ denotes the set of points assigned to centroid Œº~j~‚Äã [@hastie_elements_2009].

## Methods {.smaller}

The k-means clustering algorithm is an iterative procedure that involves two steps: allocating data points to clusters and updating the cluster centroids. Below is a comprehensive breakdown of the sequential steps in the algorithm:

-   **Initialization of centroids**. Random initialization selects ùëò initial centroids at random from the dataset. Every centroid corresponds to the original center of a cluster. The algorithm being referred to is called "k-means++" is a refined technique that distributes the initial centroids in order to enhance the performance of the algorithm. The initial centroid is selected at random, whereas the following centroids are chosen according to a probability that is directly proportionate to their distance from the nearest existing centroid.

-   **Assignment of data points to nearest centroids.** Compute the distance from each data point to every centroid. Popular distance measurements include Euclidean distance, Manhattan distance, and cosine similarity. Allocate each data point to the cluster that has the closest centroid to it. This results in the formation of ùëòclusters, where each data point is assigned to a single cluster.

## Methods {.smaller}

-   **Update of centroids.** Determine the updated centroid of each cluster by computing the average of all data points assigned to that cluster. The updated centroid is calculated as the average position of the data points within the cluster. This update step recalibrates the position of the centroids to more accurately reflect the clusters produced in the assignment stage.

-   **Iteration until convergence.** Iterate the assignment and update processes until the centroids exhibit minimal variation between iterations. Convergence is usually assessed by verifying if the positions of the centroids have reached a stable state within a predetermined tolerance threshold. Alternatively, the process can be halted after reaching a predetermined number of iterations if convergence is not attained prior to that.

## Methods {.smaller}

After importing the dataset, the expression for 77 proteins data are scaled and analyzed using Principle Component Analysis to reduce the number of dimensions. Then, the optimal number of clusters is determined using the elbow method, silhouette analysis, and gap statistic.The data are then analyzed using the k-means algorithm with the default euclidean distance metric. Differences are then considered using a contingency table and heat map to identify similar and dissimilar groups. These cluster assignments are then plotted against class to visually identify cluster characteristics.

## Data Description 

The data are sourced from a 2015 paper which evaluates the effect on protein expression of the Alzheimer's drug memantine in rescuing learning in Ts65Dn trisomic mice relative to control mice. Ts65Dn mice are genetically modified to be trisomic for 2/3 of the genes orthologous to human chromosome 21 (Hsa21), making them a suitable model organism to experimentally study Down's Syndrome (DS) (jax citation). 

## Data Description 

It is suspected that memantine can be used to treat learning deficits in DS, and this rescue effect has been previously observed in the Ts65Dn model. This study evaluates the effect of these different factors on the expression of 77 different proteins involved in Alzheimer's, neuronal receptors, Hsa21 genes, and homeostatic genes. Therefore, it is expected that Ts65Dn mice treated with memantine in the learning condition will exhibit similar patterns of protein expression relative to the untreated control model in the learning condition. Protein expression data provided are normalized to total protein expression [@higuera_self-organizing_2015].

## Data Analysis



## Conclusions

Our results indicate that the mice protein expression data set exhibits
clusters which largely correspond to the learning and non-learning
behavior groups.Additionally, our results suggest that control mice in
the learning condition exhibit similar protein expression independent of
treatment with memantine. DS-model mice in the learning condition
exhibit distinct protein expression dependent upon treatment with
memantine or saline.


