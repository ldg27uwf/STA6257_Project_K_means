---
title: "Rough Draft Literature Review - Data Science Capstone"
author: "Lindsay Guyette"
date: '`r Sys.Date()`'
format:
  html:
    code-fold: true
course: STA 6257 - Advanced Statistical Modeling
bibliography: references.bib # file contains bibtex for references
#always_allow_html: true # this allows to get PDF with HTML features
self-contained: true
execute: 
  warning: false
  message: false
editor: 
  markdown: 
    wrap: 72
---

## Objectives

The objectives of this review are threefold: to provide a comprehensive
overview of K-means clustering, to discuss its methodology,
applications, and advancements, and to identify the challenges and
future research directions. In this literature review, we aim to give an
in-depth analysis of K-means clustering, examine its various aspects and
practical uses, and highlight the current challenges along with
potential areas for future research.

## Introduction

[@zelasky_identifying_2023]

#### *K-means Clustering*

*Definition of Clustering*

Clustering is the process of grouping similar objects or data points
together based on their characteristics or attributes. Clustering is an
unsupervised learning technique employed in data mining and machine
learning to categorize a collection of items based on their similarity.
The goal is to create groupings, or clusters, where objects within the
same cluster are more alike to each other than to objects in other
clusters. Clustering aims to identify inherent clusters in a dataset
where the data points within each cluster exhibit a strong resemblance,
yet the clusters themselves are clearly dissimilar from one another.

The similarity of data points is commonly assessed using a distance
metric, such as Euclidean distance, Manhattan distance, or cosine
similarity. The choice of metric depends on the characteristics of the
data and the specific clustering technique employed.

#### ***Definition of k-Means Clustering***

The term "k-Means Clustering" refers to a method used in data analysis
and machine learning to partition a set of data points into k distinct
clusters. k-Means clustering is a highly popular and extensively
utilized approach for clustering. The objective is to divide a dataset
into k clusters, where k is a predetermined number of clusters. The
method operates in an iterative manner, assigning each data point to one
of k clusters based on the given attributes. The main concept is to
establish k centroids, representing each cluster, and allocate each data
point to the centroid that is closest to it. This allocation is done in
a way that minimizes the total squared distances between the data points
and their respective centroids.

#### ***Key Concepts of k-Means Clustering***

-   **Centroid**: The centroid of a cluster represents the average
    position of all the points within that cluster. Every cluster in the
    k-means algorithm is associated with a centroid, which serves as a
    central point that represents the cluster.

-   **Inertia:** Referred to as within-cluster sum of squares,
    quantifies the effectiveness of cluster formation. Smaller inertia
    values suggest superior clustering performance.

-   **Convergence:** The k-means method continues to iterate until it
    reaches convergence, which is when the centroids stop changing
    considerably. This indicates that the clusters have become stable.

-   **Distance Metric:** Choice of distance measure, such as Euclidean
    distance, impacts the formation of clusters. Euclidean distance is
    the typical metric employed in k-means.

#### ***Key Parameters of k-Means Clustering***

-   **Cluster Count (k):** The desired number of clusters and centroids
    to be generated. Optimal cluster selection is of utmost importance
    and can be facilitated by techniques such as the elbow approach or
    silhouette analysis.

-   **Initial Centroids:** The initial positions of the centroids, which
    can be selected randomly or using more sophisticated initialization
    methods such as k-means++ to enhance the speed of convergence and
    the quality of the solution.

-   **Maximum Iterations:** The highest number of iterations that the
    algorithm will execute if it has not achieved convergence before
    reaching this limit.

-   **Tolerance:** A criterion used to establish when convergence has
    been achieved. The algorithm terminates if the difference between
    the centroids is below the specified tolerance.

#### ***Algorithmic Steps***

The k-means clustering algorithm is an iterative procedure that involves
two steps: allocating data points to clusters and updating the cluster
centroids. Below is a comprehensive breakdown of the sequential steps in
the algorithm:

1.  **Initialization of centroids.**

Random initialization selects ùëò initial centroids at random from the
dataset. Every centroid corresponds to the original center of a cluster.
The algorithm being referred to is called "k-means++" is a refined
technique that distributes the initial centroids in order to enhance the
performance of the algorithm. The initial centroid is selected at
random, whereas the following centroids are chosen according to a
probability that is directly proportionate to their distance from the
nearest existing centroid.

2.  **Assignment of data points to nearest centroids.**

Compute the distance from each data point to every centroid. Popular
distance measurements include Euclidean distance, Manhattan distance,
and cosine similarity. Allocate each data point to the cluster that has
the closest centroid to it. This results in the formation of ùëò clusters,
where each data point is assigned to a single cluster.

3.  **Update of centroids.**

Determine the updated centroid of each cluster by computing the average
of all data points assigned to that cluster. The updated centroid is
calculated as the average position of the data points within the
cluster. This update step recalibrates the position of the centroids to
more accurately reflect the clusters produced in the assignment stage.

4.  **Iteration until convergence.**

Iterate the assignment and update processes until the centroids exhibit
minimal variation between iterations. Convergence is usually assessed by
verifying if the positions of the centroids have reached a stable state
within a predetermined tolerance threshold. Alternatively, the process
can be halted after reaching a predetermined number of iterations if
convergence is not attained prior to that.

Mathematical Formulation The k-means clustering algorithm can be
analytically defined as an optimization problem. The objective is to
divide a collection of n data points into k clusters in a manner that
minimizes the sum of squares inside each cluster (WCSS). The process
entails the following steps: Objective function (minimization of
within-cluster variance). The goal of k-means is to minimize the total
sum of squared distances between each data point and its corresponding
cluster centroid. The within-cluster sum of squares (WCSS) represents
this.

where: C~j~ is the set of data points assigned to cluster j, x~i~ is a
data point, Œº~j‚Äã~ is the centroid of cluster j, ‚à•x~i~‚àíŒº~j~‚à• is the
Euclidean distance between data point x~i~‚Äã and centroid Œº~j~‚Äã.
Mathematical representation of the algorithm. Algorithm Steps in
Mathematical Terms Initialization Randomly choose k initial centroids
Œº~1~,Œº~2~,...,Œº~k‚Äã~ from the dataset {x~1~,x~2~,...,x~n~}. Assignment
Step Assign each data point x~i‚Äã~ to the nearest centroid Œº~j~‚Äã. This can
be mathematically expressed as: C~j~ = {x~i~ : ‚à•x~i~‚àíŒº~j~‚à•2 ‚â§
‚à•x~i~‚àíŒº~l~‚à•2 for all l, 1 ‚â§ l ‚â§ k} Here, C~j‚Äã~ denotes the set of points
assigned to centroid Œº~j~‚Äã.

## Real World Applications

**Bioinformatics**

Bioinformatics refers to the usage of analytical techniques to interpret
different types of biological data. These datasets can be large or
small, containing information about genomic sequences, gene expression,
and protein expression, among other biological characteristics. This
information can then be used to draw conclusions about basic biological
processes, disease states, and gene therapies, among other applications
[@bayat_bioinformatics_2002]. K-means clustering is one type of data
analysis technique that can be used to group differential gene/protein
expression according to specific phenotypes, or physical presentations
of biological traits. For instance, this can be used to assign cells to
specific types based on single-cell RNA sequencing data, which measures
the total gene expression for thousands of genes within a single cell.
Yang et al., 2017 utilized k-means clustering to analyze the scRNA
sequencing data of hundreds of cell types to develop a novel algorithm
that identifies the optimal sets of genes to cluster single cells into
distinct biological groups.

**Sociology**

Additionally, k-means clustering can be applied to population-level data
to determine significant groupings related to socioeconomic outcomes.
The factors related to socioeconomic mobility were evaluated in a 2023
study using longitudinal data from the Opportunity Atlas project. Here,
k-means clustering revealed differences in socioeconomic mobility
related to geographic location, income, and neighborhood factors such as
poverty rate and incarceration rates [@zelasky_identifying_2023].

**Market Research and Customer Segmentation**

K-means clustering is used in market segmentation to group customers
with similar characteristics, enabling businesses to target specific
segments effectively. Companies can segment their customer base based on
purchasing behavior, identifying groups to tailor marketing strategies
and promotions. In the financial sector, k-means can segment customers
by spending patterns and risk profiles, helping banks design targeted
financial products. Entertainment and streaming companies can use
k-means to segment customers by their viewing preferences, making
personalized content recommendations. By identifying specific clusters,
businesses can optimize marketing efforts and improve customer
engagement.

**Anomaly detection and Pattern recognition.**

K-means clustering is used for anomaly detection and pattern recognition
across various fields. In cybersecurity, it identifies unusual network
activity, indicating potential threats. In finance, k-means detects
fraudulent transactions by identifying deviations from typical patterns.
In healthcare, it spots anomalies in patient data, indicating rare
diseases or unusual treatment reactions. In manufacturing, k-means
identifies defective products by highlighting outliers in quality
control data. These applications enhance the ability to detect
irregularities and recognize patterns, improving decision-making and
operational efficiency.

# **Variations and Enhancements of k-Means**

## **Initialization Methods**

Initialization methods are crucial for the performance of k-means
clustering. Random initialization involves starting with randomly chosen
cluster centers, which can sometimes lead to poor clustering outcomes or
slow convergence. The k-means++ initialization method enhances this by
choosing initial cluster centers more strategically, greatly improving
clustering quality and convergence speed. Other advanced initialization
techniques include things like PCA-based initialization, which uses
principal component analysis to select starting centers, or
density-based methods that consider data distribution for better initial
placement.

## **Distance Metrics**

The choice of distance metric significantly impacts the clustering
results of k-means. Euclidean distance is the most commonly used metric
and works well for many applications. However, for certain datasets,
other metrics like Manhattan distance, which measures distance along
axes at right angles, may be more appropriate. Additionally, various
other metrics can be employed to fit specific data types and problem
requirements, enhancing the flexibility and applicability of k-means to
diverse datasets.

## **Scalability and Efficiency Improvements**

As datasets grow larger, the efficiency of k-means becomes increasingly
important. Accelerated k-means algorithms have been developed to speed
up the standard process, typically by optimizing the computational steps
involved. Approximate k-means offers faster, albeit less precise,
clustering suitable for extremely large datasets where exact precision
is less critical. Furthermore, parallel and distributed k-means
techniques allow the algorithm to run on multiple machines
simultaneously, significantly improving scalability and reducing
computation time.

## **Handling Different Data Types**

K-means can be adapted to handle various data types beyond purely
numeric data. For mixed numeric and categorical data, specialized
algorithms can process both types simultaneously, maintaining clustering
effectiveness. Text and document clustering represent another
application where k-means can be adapted, often using techniques such as
TF-IDF to convert text into numeric form that the algorithm can process.
These adaptations make k-means a versatile tool for a broad range of
data types.

## **Clustering Quality and Validation**

Assessing the quality of clustering is essential for ensuring good
outcomes. Internal validation indices, such as the silhouette score,
evaluate clustering quality based on the data alone, providing insight
into how well the clusters are formed. External validation indices, like
the adjusted Rand index, compare the clustering results to external or
known classifications, offering a benchmark for performance. Stability
and robustness measures are also important, as they assess how
consistent the clustering results are under different conditions or
inputs, ensuring reliability and robustness of the algorithm.

## Data Description

Edgar Anderson, an American botanist, collected data to study the
morphological differences in iris flowers. He collected 50 samples each
from three different species: Setosa, Versicolor, and Virginica. The
dataset consists of measurements of these three species, with four
attributes for each sample: sepal length, sepal width, petal length, and
petal width. The dataset was first introduced into the stats field by
British biologist and statistician Ronald A. Fisher in his research
paper \"The use of multiple measurements in taxonomic problems\". He
used this dataset to demonstrate linear discriminant analysis. Since
then, this dataset has become a classic dataset in the field of machine
learning and stats.

The Iris dataset is preloaded in R and is often used for predictive
modeling. In our project, we aim to use the Iris dataset to understand
how the K-means algorithm groups the flowers based on their features
(sepal and petal dimensions). We will also provide a visual
representation of the clusters, which will help in visualizing the
effectiveness of the K-means clustering in identifying natural groupings
within the data.

## References
